{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maiapiechocki/FER2013/blob/main/FER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "p-tSJjojpmSr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, ReLU, BatchNormalization, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # imagedategenerator does augmenting + preprocess data\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hh1crypE45b",
        "outputId": "bf38784a-72b5-4539-aa49-cd1c8bcf0286"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 22 08:00:57 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0              32W /  70W |    677MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!kaggle datasets download -d msambare/fer2013\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEdO8Hs2qCTB",
        "outputId": "675a7431-2af5-46df-9d27-032defc9093a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n",
            "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n",
            "License(s): DbCL-1.0\n",
            "fer2013.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip fer2013.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6nUlMPKqibo",
        "outputId": "47c1b244-3c6e-4de4-f0e4-9feee5d44216"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  fer2013.zip\n",
            "replace test/angry/PrivateTest_10131363.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace test/angry/PrivateTest_10304478.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace test/angry/PrivateTest_1054527.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace test/angry/PrivateTest_10590091.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace test/angry/PrivateTest_1109992.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace test/angry/PrivateTest_11296953.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9d6Mbyk8hem",
        "outputId": "b9d767c9-adb4-40db-adf6-7cffe6526961"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model.keras  fer2013.zip  sample_data  test  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm best_model.keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M4ZywBbFeN8",
        "outputId": "66deb31e-47b8-4978-c2c6-dce5df2bde99"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'best_model.keras': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"train\"\n",
        "test_path = \"test\""
      ],
      "metadata": {
        "id": "Ms-VCe3GyDQu"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(train_path))\n",
        "print(os.listdir(test_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bd55X5v7grJ",
        "outputId": "37dac752-c31c-4771-da3c-d5ee8d124119"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['surprise', 'sad', 'neutral', 'angry', 'disgust', 'happy', 'fear']\n",
            "['surprise', 'sad', 'neutral', 'angry', 'disgust', 'happy', 'fear']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data augmentation\n",
        "\n",
        "# define instance of imagedatagenerator for training with augmentation\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, # normalize image pixels\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=20,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# load and augment training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory = train_path,\n",
        "    target_size = (48, 48),\n",
        "    batch_size = 64,\n",
        "    shuffle = True,\n",
        "    color_mode = \"grayscale\",\n",
        "    class_mode = \"categorical\",\n",
        "    subset = \"training\"\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory = test_path,\n",
        "    target_size = (48,48),\n",
        "    batch_size = 64,\n",
        "    shuffle = True,\n",
        "    class_mode = 'categorical',\n",
        "    color_mode = 'grayscale'\n",
        "    )\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    validation_split = 0.2)\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    directory = train_path,\n",
        "    target_size = (48, 48),\n",
        "    batch_size = 64,\n",
        "    color_mode = \"grayscale\",\n",
        "    class_mode = \"categorical\",\n",
        "    subset = \"validation\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO1YDOFY7j9B",
        "outputId": "c04fcd7c-741c-4a27-b6e0-bccf4b531f20"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22968 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n",
            "Found 5741 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def create_model():\n",
        "    weight_decay = 1e-4\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "\n",
        "    model.add(Conv2D(64, (4, 4), padding='same', kernel_regularizer=l2(weight_decay), input_shape=(48, 48, 1)))\n",
        "    model.add(ReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(64, (4, 4), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "    model.add(ReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (4, 4), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "    model.add(ReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(128, (4, 4), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "    model.add(ReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (4, 4), padding='same', kernel_regularizer=l2(weight_decay)))\n",
        "    model.add(ReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "    # add GAP to reduce number of parameters  by reducing\n",
        "    # each feature map to a single averaged value\n",
        "\n",
        "    # fully connected layer\n",
        "    model.add(tf.keras.layers.Dense(128, activation='linear'))  # linear dense layer\n",
        "    model.add(ReLU())\n",
        "\n",
        "    # output layer\n",
        "    model.add(tf.keras.layers.Dense(7, activation='softmax'))  # softmax for multi-class classification\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model()\n"
      ],
      "metadata": {
        "id": "Nwuw8mE9-XcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf01eed-dbd5-4455-d537-16c4ab8e4d4b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate scheduler\n",
        "initial_learning_rate = 0.001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=initial_learning_rate,\n",
        "    decay_steps=100000,  # number of steps b4 the learning rate is decayed\n",
        "    decay_rate=0.9,\n",
        "    staircase=True       # the decay should be applied in discrete steps (if True)\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n"
      ],
      "metadata": {
        "id": "v9BGeYSh2FE_"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',  # since multi-class classification problem\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "xJJRBx-R3DY5"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "\n",
        "# earlystopping to stop training if validation loss does not improve\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    'best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# reduceLR to reduce learning rate if validation accuracy stops improving\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "49Dk6aiV3N2_"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = validation_generator.samples // validation_generator.batch_size\n"
      ],
      "metadata": {
        "id": "zV8Y12m_4dN4"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model with callbacks and steps per epoch\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    callbacks=[early_stopping, model_checkpoint, reduce_lr]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1QGU71wE3lI5",
        "outputId": "7c5f2483-9b5a-4537-d53f-54d14869f68f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2353 - loss: 1.9157\n",
            "Epoch 1: val_loss improved from inf to 1.89761, saving model to best_model.keras\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 71ms/step - accuracy: 0.2354 - loss: 1.9155 - val_accuracy: 0.1543 - val_loss: 1.8976 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.2656 - loss: 1.7811"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss did not improve from 1.89761\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2656 - loss: 1.7811 - val_accuracy: 0.1556 - val_loss: 1.9594 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3151 - loss: 1.7559\n",
            "Epoch 3: val_loss improved from 1.89761 to 1.67402, saving model to best_model.keras\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - accuracy: 0.3151 - loss: 1.7558 - val_accuracy: 0.3464 - val_loss: 1.6740 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.3906 - loss: 1.6671\n",
            "Epoch 4: val_loss improved from 1.67402 to 1.62158, saving model to best_model.keras\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.3906 - loss: 1.6671 - val_accuracy: 0.5333 - val_loss: 1.6216 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3753 - loss: 1.6328\n",
            "Epoch 5: val_loss did not improve from 1.62158\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.3753 - loss: 1.6327 - val_accuracy: 0.3729 - val_loss: 1.6589 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.3906 - loss: 1.5613\n",
            "Epoch 6: val_loss improved from 1.62158 to 1.48402, saving model to best_model.keras\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.3906 - loss: 1.5613 - val_accuracy: 0.4444 - val_loss: 1.4840 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4262 - loss: 1.5495\n",
            "Epoch 7: val_loss improved from 1.48402 to 1.44062, saving model to best_model.keras\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.4262 - loss: 1.5495 - val_accuracy: 0.4872 - val_loss: 1.4406 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.3281 - loss: 1.6788\n",
            "Epoch 8: val_loss improved from 1.44062 to 1.36179, saving model to best_model.keras\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.3281 - loss: 1.6788 - val_accuracy: 0.5111 - val_loss: 1.3618 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4512 - loss: 1.4918\n",
            "Epoch 9: val_loss did not improve from 1.36179\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.4512 - loss: 1.4917 - val_accuracy: 0.4809 - val_loss: 1.4758 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.4531 - loss: 1.5017\n",
            "Epoch 10: val_loss did not improve from 1.36179\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4531 - loss: 1.5017 - val_accuracy: 0.4889 - val_loss: 1.3669 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m356/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4780 - loss: 1.4364\n",
            "Epoch 11: val_loss did not improve from 1.36179\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.4780 - loss: 1.4364 - val_accuracy: 0.5014 - val_loss: 1.3996 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.5625 - loss: 1.3675\n",
            "Epoch 12: val_loss did not improve from 1.36179\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57us/step - accuracy: 0.5625 - loss: 1.3675 - val_accuracy: 0.4000 - val_loss: 1.4705 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4931 - loss: 1.4101\n",
            "Epoch 13: val_loss improved from 1.36179 to 1.28465, saving model to best_model.keras\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - accuracy: 0.4931 - loss: 1.4102 - val_accuracy: 0.5434 - val_loss: 1.2847 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.5312 - loss: 1.4265\n",
            "Epoch 14: val_loss improved from 1.28465 to 1.28023, saving model to best_model.keras\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.5312 - loss: 1.4265 - val_accuracy: 0.5111 - val_loss: 1.2802 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m356/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5033 - loss: 1.4015\n",
            "Epoch 15: val_loss did not improve from 1.28023\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.5033 - loss: 1.4016 - val_accuracy: 0.5286 - val_loss: 1.3394 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.5625 - loss: 1.4152\n",
            "Epoch 16: val_loss did not improve from 1.28023\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 1.4152 - val_accuracy: 0.5333 - val_loss: 1.3817 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5060 - loss: 1.3936\n",
            "Epoch 17: val_loss did not improve from 1.28023\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - accuracy: 0.5060 - loss: 1.3936 - val_accuracy: 0.4958 - val_loss: 1.3841 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.5625 - loss: 1.2657\n",
            "Epoch 18: val_loss improved from 1.28023 to 1.16276, saving model to best_model.keras\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.5625 - loss: 1.2657 - val_accuracy: 0.6889 - val_loss: 1.1628 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m356/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5069 - loss: 1.3999\n",
            "Epoch 19: val_loss did not improve from 1.16276\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.5069 - loss: 1.3999 - val_accuracy: 0.5551 - val_loss: 1.2857 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.5156 - loss: 1.3902\n",
            "Epoch 20: val_loss did not improve from 1.16276\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5156 - loss: 1.3902 - val_accuracy: 0.6222 - val_loss: 1.2853 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5231 - loss: 1.3778\n",
            "Epoch 21: val_loss did not improve from 1.16276\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.5231 - loss: 1.3777 - val_accuracy: 0.5562 - val_loss: 1.2909 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m  1/358\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.6875 - loss: 1.1598\n",
            "Epoch 22: val_loss did not improve from 1.16276\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 1.1598 - val_accuracy: 0.5556 - val_loss: 1.2537 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5277 - loss: 1.3611\n",
            "Epoch 23: val_loss did not improve from 1.16276\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "This optimizer was created with a `LearningRateSchedule` object as its `learning_rate` constructor argument, hence its learning rate is not settable. If you need the learning rate to be settable, you should instantiate the optimizer with a float `learning_rate` argument.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-27187f6f3f6a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model with callbacks and steps per epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mlearning_rate\u001b[0;34m(self, learning_rate)\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateSchedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             ):\n\u001b[0;32m--> 544\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    545\u001b[0m                     \u001b[0;34m\"This optimizer was created with a `LearningRateSchedule`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                     \u001b[0;34m\" object as its `learning_rate` constructor argument, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: This optimizer was created with a `LearningRateSchedule` object as its `learning_rate` constructor argument, hence its learning rate is not settable. If you need the learning rate to be settable, you should instantiate the optimizer with a float `learning_rate` argument."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, f1_score\n",
        "\n",
        "evaluation = model.evaluate(validation_generator)\n",
        "print(f\"Model Loss: {evaluation[0]:.4f}\")\n",
        "print(f\"Model Accuracy: {evaluation[1] * 100:.2f}%\")\n",
        "\n",
        "\n",
        "y_true = validation_generator.classes\n",
        "y_pred = model.predict(validation_generator)\n",
        "y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
        "\n",
        "y_pred_classes = y_pred_classes.numpy()  # convert from tf tensor to np array\n",
        "\n",
        "recall = recall_score(y_true, y_pred_classes, average='macro')\n",
        "f1 = f1_score(y_true, y_pred_classes, average='macro')\n",
        "\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKF8BnHY59_7",
        "outputId": "84c3a5c2-8999-4e20-c490-a6dcaaf44348"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.5477 - loss: 1.3214\n",
            "Model Loss: 1.3248\n",
            "Model Accuracy: 54.61%\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "Recall: 0.1415\n",
            "F1-Score: 0.1352\n"
          ]
        }
      ]
    }
  ]
}